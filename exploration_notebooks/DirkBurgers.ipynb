{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from ipywidgets import interact, IntSlider\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "# m = np.array([10,100,1000])\n",
    "m = 1000\n",
    "x = np.array([-1/2, -1/6, 1/6, 1/2])\n",
    "y = np.array([1/4, 1/30, 1/30, 1/4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def indicator(condition):\n",
    "    return condition.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-Lyaer ReLu Neural Network\n",
    "def twoLayerReluNet(alpha_m, a, w, b, x):\n",
    "    return 1/alpha_m * np.sum(a * relu(w * x + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We use the following to fix the values of gamma, gamma_prime and alpha_m\n",
    "gamma = 3/2\n",
    "gamma_prime = -1/2\n",
    "\n",
    "alpha_m = m**(gamma - gamma_prime)\n",
    "kappa = m**(-gamma)\n",
    "kappa_prime = m**(-gamma_prime)\n",
    "\n",
    "beta_1m = math.sqrt(kappa*kappa_prime*alpha_m)\n",
    "beta_2m = math.sqrt((kappa/kappa_prime)*alpha_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Typical parameter gradients\n",
    "\n",
    "# def gradient_flow(a,w,b):\n",
    "#     grad_a = -(1/n) * np.sum([[(1/alpha_m) * relu((w*x[i])+b) * gradRiskwrtFunction(a,w,b,i)] for i in range(n)], axis=0).reshape(m)\n",
    "#     grad_w = -(1/n) * np.sum([[(1/alpha_m) * a*x[i] * indicator(w*x[i]+b > 0) * gradRiskwrtFunction(a,w,b,i)] for i in range(n)], axis=0).reshape(m)\n",
    "#     grad_b = -(1/n) * np.sum([[(1/alpha_m) * a * indicator(w*x[i]+b > 0) * gradRiskwrtFunction(a,w,b,i)] for i in range(n)], axis=0).reshape(m)\n",
    "#     return grad_a, grad_w, grad_b\n",
    "\n",
    "# def gradRiskwrtFunction(a,w,b,i):\n",
    "#     return twoLayerReluNet(alpha_m, a, w, b, x[i]) - y[i]\n",
    "\n",
    "def gradient_flow(a,w,b):\n",
    "    # Compute wx_plus_b for all i and j\n",
    "    wx_plus_b = np.outer(x,w) + b  # Shape: (n, m)\n",
    "\n",
    "    # Apply ReLU activation\n",
    "    relu_mask = (wx_plus_b > 0).astype(float)  # Shape: (n, m)\n",
    "    relu = wx_plus_b * relu_mask  # Apply the mask\n",
    "\n",
    "    # First term inside parentheses: (1 / alpha_m) * sum_j(a_j * ReLU_j)\n",
    "    term2 = (np.sum(a * relu, axis=1) / alpha_m) - y  # Shape: (n,)\n",
    "\n",
    "    # Full sum: sum relu multiplied with appropriate term2, over i\n",
    "    full_sum_a = np.sum(relu * term2[:, np.newaxis], axis=0)  # Shape: (m,)\n",
    "\n",
    "    # Multiply by aj * xi * 1{wx_plus_b > 0}\n",
    "    term1_w = (a * x[:, np.newaxis] * relu_mask)  # Shape: (n, m)\n",
    "    # Full sum: sum term1_w multiplied with appropriate term2, over i\n",
    "    full_sum_w = np.sum(term1_w * term2[:, np.newaxis], axis=0)  # Shape: (m,)\n",
    "\n",
    "    # Multiply by aj * 1{wx_plus_b > 0}\n",
    "    term1_b = (a * relu_mask)  # Shape: (n, m)\n",
    "    # Full sum: sum term1_b multiplied with appropriate term2, over i\n",
    "    full_sum_b = np.sum(term1_b * term2[:, np.newaxis], axis=0)  # Shape: (m,)\n",
    "\n",
    "    # Scale by constants\n",
    "    grad_a = -full_sum_a / (n * alpha_m)  # Final shape: (m,)\n",
    "    grad_w = -full_sum_w / (n * alpha_m)  # Final shape: (m,)\n",
    "    grad_b = -full_sum_b / (n * alpha_m)  # Final shape: (m,)\n",
    "\n",
    "    return grad_a, grad_w, grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalised gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalized parameter gradients\n",
    "\n",
    "# def normalised_gradient_flow(a,w,b):\n",
    "#     grad_a = - kappa_prime * (1/n) * np.sum([[kappa * relu((w*x[i])+b) * gradRiskwrtFunction(a,w,b,i)] for i in range(n)], axis=0).reshape(m)\n",
    "#     grad_w = - kappa_prime * np.sum([[kappa * a*x[i] * indicator(w*x[i]+b > 0) * gradRiskwrtFunction(a,w,b,i)] for i in range(n)], axis=0).reshape(m)\n",
    "#     grad_b = - kappa_prime * np.sum([[kappa * a * indicator(w*x[i]+b > 0) * gradRiskwrtFunction(a,w,b,i)] for i in range(n)], axis=0).reshape(m)\n",
    "#     return grad_a, grad_w, grad_b\n",
    "\n",
    "# def normalised_gradRiskwrtFunction(a,w,b,i):\n",
    "#     return kappa * np.sum([[a[j] * relu((w[j]*x[i])+b[j]) - y[i]] for j in range(m)], axis=0)\n",
    "\n",
    "# def normalise_param(a,w,b,t):\n",
    "#     return a/beta_1m, w/beta_2m, b/beta_2m, t/(beta_1m * beta_2m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(step_size, steps):\n",
    "    \n",
    "    a = np.random.normal(loc=0, scale=beta_1m, size=math.ceil(m))\n",
    "    w = np.random.normal(loc=0, scale=beta_2m, size=math.ceil(m))\n",
    "    b = np.random.normal(loc=0, scale=beta_2m, size=math.ceil(m))\n",
    "\n",
    "    a_values = []\n",
    "    w_values = []\n",
    "    b_values = []\n",
    "\n",
    "    #for n in range(math.ceil(time/step_size)):\n",
    "    for n in range(steps): \n",
    "        grad_a, grad_w, grad_b = gradient_flow(a,w,b)\n",
    "        a = a + step_size * grad_a\n",
    "        w = w + step_size * grad_w\n",
    "        b = b + step_size * grad_b\n",
    "\n",
    "        # Save the current values of a, w, and b\n",
    "        a_values.append(a.copy())\n",
    "        w_values.append(w.copy())\n",
    "        b_values.append(b.copy())\n",
    "\n",
    "        print('Completed step  %d / %d' % (n, steps)) \n",
    "\n",
    "    return a_values, w_values, b_values\n",
    "\n",
    "def gradient_descent_symmetric(step_size, steps):\n",
    "    \n",
    "    a = np.random.normal(loc=0, scale=beta_1m, size=math.ceil(m/2))\n",
    "    w = np.random.normal(loc=0, scale=beta_2m, size=math.ceil(m/2))\n",
    "    b = np.random.normal(loc=0, scale=beta_2m, size=math.ceil(m/2))\n",
    "\n",
    "    a = np.concatenate((a, a))\n",
    "    w = np.concatenate((w, -w))\n",
    "    b = np.concatenate((b, b))\n",
    "\n",
    "    a_values = []\n",
    "    w_values = []\n",
    "    b_values = []\n",
    "\n",
    "    #for n in range(math.ceil(time/step_size)):\n",
    "    for n in range(steps): \n",
    "        grad_a, grad_w, grad_b = gradient_flow(a,w,b)\n",
    "        a = a + step_size * grad_a\n",
    "        w = w + step_size * grad_w\n",
    "        b = b + step_size * grad_b\n",
    "\n",
    "        # Save the current values of a, w, and b\n",
    "        a_values.append(a.copy())\n",
    "        w_values.append(w.copy())\n",
    "        b_values.append(b.copy())\n",
    "\n",
    "        print('Completed step  %d / %d' % (n, steps)) \n",
    "\n",
    "    return a_values, w_values, b_values\n",
    "        \n",
    "# Assuming beta_1m, beta_2m, m, and gradient_flow are defined\n",
    "n_steps = 200000\n",
    "# a_values, w_values, b_values = gradient_descent_vector(4000, n_steps)\n",
    "\n",
    "# # Convert lists to arrays for easier saving and plotting\n",
    "# a_values = np.array(a_values)\n",
    "# w_values = np.array(w_values)\n",
    "# b_values = np.array(b_values)\n",
    "\n",
    "# # Save the arrays to disk\n",
    "# np.save('a_values_vector.npy', a_values)\n",
    "# np.save('w_values_vector.npy', w_values)\n",
    "# np.save('b_values_vector.npy', b_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Cell generating function development over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6762feba3c5d4ab8a6c93c573f582f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=199999), Output()), _dom_classes=('widget-inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_values(index)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the arrays from the .npy files\n",
    "a_values = np.load('weights\\\\a_values_vector_sym.npy')\n",
    "w_values = np.load('weights\\\\w_values_vector_sym.npy')\n",
    "b_values = np.load('weights\\\\b_values_vector_sym.npy')\n",
    "\n",
    "# Define the range of x\n",
    "x_graph = np.linspace(-0.5, 0.5, 800)\n",
    "y_graph = np.zeros(len(x_graph))\n",
    "\n",
    "# Define the function to plot the values at a given index\n",
    "def plot_values(index):\n",
    "    a = a_values[index]\n",
    "    w = w_values[index]\n",
    "    b = b_values[index]\n",
    "\n",
    "    # Compute the corresponding y values\n",
    "    for i in range(len(x_graph)):\n",
    "        y_graph[i] = twoLayerReluNet(alpha_m,a,w,b,x_graph[i])\n",
    "\n",
    "    # Plot the function\n",
    "    plt.scatter(x, y, c='orange', alpha=0.5)\n",
    "    plt.plot(x_graph, y_graph)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.grid(True)\n",
    "    plt.xlim(-0.6, 0.6)\n",
    "    plt.ylim(-0.01, 0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Create an interactive slider\n",
    "interact(plot_values, index=IntSlider(min=0, max=len(a_values)-1, step=1, value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Cell generating min and max y values over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to plot the values at a given index\n",
    "def get_values(index):\n",
    "    a = a_values[index]\n",
    "    w = w_values[index]\n",
    "    b = b_values[index]\n",
    "    \n",
    "    y_graph = np.zeros((int)(400))\n",
    "    # Compute the corresponding y values\n",
    "    for i in range(len(x_graph)):\n",
    "        y_graph[i] = twoLayerReluNet(alpha_m,a,w,b,x_graph[i])\n",
    "\n",
    "    return np.min(y_graph), np.max(y_graph)\n",
    "\n",
    "\n",
    "x_graph = np.linspace(-0.5, 0.5, 400)\n",
    "# Initialize an array to store y values\n",
    "min_y_values = np.zeros((int)(n_steps/1000))\n",
    "max_y_values = np.zeros((int)(n_steps/1000))\n",
    "for n in range((int)(n_steps/1000)):\n",
    "    min_y_values[n], max_y_values[n] = get_values(n*1000)\n",
    "\n",
    "# Create an array of indices\n",
    "indices = np.arange(n_steps/1000)\n",
    "\n",
    "# Plot the min and max values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(indices, min_y_values, color='blue', label='Min y values')\n",
    "plt.plot(indices, max_y_values, color='red', label='Max y values')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Index x1000')\n",
    "plt.ylabel('y values')\n",
    "plt.title('Min and Max y values at index')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code cell for generating animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming a_values, w_values, and b_values are already loaded\n",
    "# a_values = np.load('weights_descent/a_values.npy')\n",
    "# w_values = np.load('weights_descent/w_values.npy')\n",
    "# b_values = np.load('weights_descent/b_values.npy')\n",
    "\n",
    "# # Example x values (replace with your actual x values)\n",
    "# x_graph = np.linspace(-0.5, 0.5, 100)\n",
    "# y_graph = np.zeros(len(x_graph))\n",
    "\n",
    "\n",
    "# # Create a figure and axis\n",
    "# fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# line, = ax.plot([], [], lw=2)\n",
    "\n",
    "# # Set limits for x and y axes\n",
    "# ax.scatter(x, y, c='orange', alpha=0.5)\n",
    "# ax.set_xlim(-0.6, 0.6)  # Set x-axis limits\n",
    "# ax.set_ylim(-0.01, 0.26)  # Set y-axis limits\n",
    "# ax.set_xlabel('x')\n",
    "# ax.set_ylabel('y')\n",
    "# ax.set_title('Animated Plot')\n",
    "# ax.grid(True)\n",
    "\n",
    "# # Initialization function to set up the background of each frame\n",
    "# def init():\n",
    "#     line.set_data([], [])\n",
    "#     return line,\n",
    "\n",
    "# # Animation function to update the plot\n",
    "# def animate(i):\n",
    "#     a = a_values[i*1000]\n",
    "#     w = w_values[i*1000]\n",
    "#     b = b_values[i*1000]\n",
    "    \n",
    "#     # Compute the corresponding y values\n",
    "#     for j in range(len(x_graph)):\n",
    "#         y_graph[j] = twoLayerReluNet(alpha_m,a,w,b,x_graph[j])\n",
    "    \n",
    "#     line.set_data(x_graph, y_graph)\n",
    "#     return line,\n",
    "\n",
    "# # Create the animation\n",
    "# anim = FuncAnimation(fig, animate, init_func=init, frames=(int)(len(a_values)/1000), interval=1, blit=True, repeat=True, repeat_delay=100)\n",
    "\n",
    "# # Save the animation\n",
    "# anim.save('animations/animation.html', writer='html')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
