{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from ipywidgets import interact, IntSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple paramters and data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "m = 1000\n",
    "x = np.array([-1/2, -1/6, 1/6, 1/2])\n",
    "y = np.array([1/4, 1/30, 1/30, 1/4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def indicator(condition):\n",
    "    return condition.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-layer ReLU neural network\n",
    "\n",
    "$ f_m(x;\\theta) = \\frac{1}{\\alpha_m} \\sum_{j=1}^m a_j(w_j x + b_j)_{+}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-Lyaer ReLu Neural Network\n",
    "def twoLayerReluNet(alpha_m, a, w, b, x):\n",
    "    return 1/alpha_m * np.sum(a * relu(w * x + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisation of weights\n",
    "\n",
    "$a_j^0 \\sim \\mathcal{N}(0,\\beta^2_{1m})$ and $b_j^0, w_j^0 \\sim \\mathcal{N}(0,\\beta^2_{2m})$\n",
    "\n",
    "through normalisation we define\n",
    "\n",
    "$\\kappa := \\frac{\\beta_{1m} \\beta_{2m}}{\\alpha_m}$, $\\kappa' := \\frac{\\beta_{1m}}{\\beta_{2m}}$\n",
    "\n",
    "and\n",
    "\n",
    "$\\gamma := \\lim_{m \\rightarrow \\infty} \\frac{\\log{\\kappa}}{\\log{m}}$, $\\gamma' := \\lim_{m \\rightarrow \\infty} \\frac{\\log{\\kappa'}}{\\log{m}}$\n",
    "\n",
    "We take that parameters $a_m, \\beta_{1m}, \\beta_{2m}$ are taken to have a power-law relation to $m$ and so we are able to choose $\\gamma$ and $\\gamma'$ such that the $a$-lag training regime is used.\n",
    "\n",
    "<small>  T. Luo, Z.-Q. J. Xu, Z. Ma, and Y. Zhang. Phase diagram for two-layer relu neu\n",
    "ral networks at innite-width limit . In: Journal of Machine Learning Research 22.71\n",
    " (2021), pp. 147.</small>\n",
    "\n",
    "<small>  Z.Chen,Y.Li,T.Luo,Z.Zhou,andZ.-Q. J. Xu. Phase diagram of initial condensation\n",
    " for two-layer neural networks . In: arXiv preprint arXiv:2303.06561 (2023).</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We use the following to fix the values of gamma, gamma_prime and alpha_m\n",
    "gamma = 3/2\n",
    "gamma_prime = -1/2\n",
    "\n",
    "alpha_m = m**(gamma - gamma_prime)\n",
    "kappa = m**(-gamma)\n",
    "kappa_prime = m**(-gamma_prime)\n",
    "\n",
    "beta_1m = math.sqrt(kappa*kappa_prime*alpha_m)\n",
    "beta_2m = math.sqrt((kappa/kappa_prime)*alpha_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient flow\n",
    "\n",
    "Empirical Risk equation - $\\mathcal{R}(\\theta) := \\frac{1}{2n} \\sum_{i=1}^m (f_m(x_i; \\theta) - y_i)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Typical parameter gradients\n",
    "def gradient_flow(a,w,b):\n",
    "    # Compute wx_plus_b for all i and j\n",
    "    wx_plus_b = np.outer(x,w) + b  # Shape: (n, m)\n",
    "\n",
    "    # Apply ReLU activation\n",
    "    relu_mask = (wx_plus_b > 0).astype(float)  # Shape: (n, m)\n",
    "    relu = wx_plus_b * relu_mask  # Apply the mask\n",
    "\n",
    "    # First term inside parentheses: (1 / alpha_m) * sum_j(a_j * ReLU_j)\n",
    "    term2 = (np.sum(a * relu, axis=1) / alpha_m) - y  # Shape: (n,)\n",
    "\n",
    "    # Full sum: sum relu multiplied with appropriate term2, over i\n",
    "    full_sum_a = np.sum(relu * term2[:, np.newaxis], axis=0)  # Shape: (m,)\n",
    "\n",
    "    # Multiply by aj * xi * 1{wx_plus_b > 0}\n",
    "    term1_w = (a * x[:, np.newaxis] * relu_mask)  # Shape: (n, m)\n",
    "    # Full sum: sum term1_w multiplied with appropriate term2, over i\n",
    "    full_sum_w = np.sum(term1_w * term2[:, np.newaxis], axis=0)  # Shape: (m,)\n",
    "\n",
    "    # Multiply by aj * 1{wx_plus_b > 0}\n",
    "    term1_b = (a * relu_mask)  # Shape: (n, m)\n",
    "    # Full sum: sum term1_b multiplied with appropriate term2, over i\n",
    "    full_sum_b = np.sum(term1_b * term2[:, np.newaxis], axis=0)  # Shape: (m,)\n",
    "\n",
    "    # Scale by constants\n",
    "    grad_a = -full_sum_a / (n * alpha_m)  # Final shape: (m,)\n",
    "    grad_w = -full_sum_w / (n * alpha_m)  # Final shape: (m,)\n",
    "    grad_b = -full_sum_b / (n * alpha_m)  # Final shape: (m,)\n",
    "\n",
    "    return grad_a, grad_w, grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(step_size, steps):\n",
    "    \n",
    "    a = np.random.normal(loc=0, scale=beta_1m, size=math.ceil(m))\n",
    "    w = np.random.normal(loc=0, scale=beta_2m, size=math.ceil(m))\n",
    "    b = np.random.normal(loc=0, scale=beta_2m, size=math.ceil(m))\n",
    "\n",
    "    a_values = []\n",
    "    w_values = []\n",
    "    b_values = []\n",
    "\n",
    "    #for n in range(math.ceil(time/step_size)):\n",
    "    for n in range(steps): \n",
    "        grad_a, grad_w, grad_b = gradient_flow(a,w,b)\n",
    "        a = a + step_size * grad_a\n",
    "        w = w + step_size * grad_w\n",
    "        b = b + step_size * grad_b\n",
    "\n",
    "        # Save the current values of a, w, and b\n",
    "        a_values.append(a.copy())\n",
    "        w_values.append(w.copy())\n",
    "        b_values.append(b.copy())\n",
    "\n",
    "        print('Completed step  %d / %d' % (n, steps)) \n",
    "\n",
    "    return a_values, w_values, b_values\n",
    "\n",
    "def gradient_descent_symmetric(step_size, steps):\n",
    "    \n",
    "    a = np.random.normal(loc=0, scale=beta_1m, size=math.ceil(m/2))\n",
    "    w = np.random.normal(loc=0, scale=beta_2m, size=math.ceil(m/2))\n",
    "    b = np.random.normal(loc=0, scale=beta_2m, size=math.ceil(m/2))\n",
    "\n",
    "    a = np.concatenate((a, a))\n",
    "    w = np.concatenate((w, -w))\n",
    "    b = np.concatenate((b, b))\n",
    "\n",
    "    a_values = []\n",
    "    w_values = []\n",
    "    b_values = []\n",
    "\n",
    "    #for n in range(math.ceil(time/step_size)):\n",
    "    for n in range(steps): \n",
    "        grad_a, grad_w, grad_b = gradient_flow(a,w,b)\n",
    "        a = a + step_size * grad_a\n",
    "        w = w + step_size * grad_w\n",
    "        b = b + step_size * grad_b\n",
    "\n",
    "        # Save the current values of a, w, and b\n",
    "        a_values.append(a.copy())\n",
    "        w_values.append(w.copy())\n",
    "        b_values.append(b.copy())\n",
    "\n",
    "        print('Completed step  %d / %d' % (n, steps)) \n",
    "\n",
    "    return a_values, w_values, b_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming beta_1m, beta_2m, m, and gradient_flow are defined\n",
    "n_steps = 200000\n",
    "a_values, w_values, b_values = gradient_descent(4000, n_steps)\n",
    "\n",
    "# Convert lists to arrays for easier saving and plotting\n",
    "a_values = np.array(a_values)\n",
    "w_values = np.array(w_values)\n",
    "b_values = np.array(b_values)\n",
    "\n",
    "# Save the arrays to disk\n",
    "np.save('weights\\\\a_values.npy', a_values)\n",
    "np.save('weights\\\\w_values.npy', w_values)\n",
    "np.save('weights\\\\b_values.npy', b_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Cell generating function development over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6762feba3c5d4ab8a6c93c573f582f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=199999), Output()), _dom_classes=('widget-inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_values(index)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the arrays from the .npy files\n",
    "a_values = np.load('weights\\\\a_values.npy')\n",
    "w_values = np.load('weights\\\\w_values.npy')\n",
    "b_values = np.load('weights\\\\b_values.npy')\n",
    "\n",
    "# Define the range of x\n",
    "x_graph = np.linspace(-0.5, 0.5, 800)\n",
    "y_graph = np.zeros(len(x_graph))\n",
    "\n",
    "# Define the function to plot the values at a given index\n",
    "def plot_values(index):\n",
    "    a = a_values[index]\n",
    "    w = w_values[index]\n",
    "    b = b_values[index]\n",
    "\n",
    "    # Compute the corresponding y values\n",
    "    for i in range(len(x_graph)):\n",
    "        y_graph[i] = twoLayerReluNet(alpha_m,a,w,b,x_graph[i])\n",
    "\n",
    "    # Plot the function\n",
    "    plt.scatter(x, y, c='orange', alpha=0.5)\n",
    "    plt.plot(x_graph, y_graph)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.grid(True)\n",
    "    plt.xlim(-0.6, 0.6)\n",
    "    plt.ylim(-0.01, 0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Create an interactive slider\n",
    "interact(plot_values, index=IntSlider(min=0, max=len(a_values)-1, step=1, value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Cell generating min and max y values over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to plot the values at a given index\n",
    "def get_values(index):\n",
    "    a = a_values[index]\n",
    "    w = w_values[index]\n",
    "    b = b_values[index]\n",
    "    \n",
    "    y_graph = np.zeros((int)(400))\n",
    "    # Compute the corresponding y values\n",
    "    for i in range(len(x_graph)):\n",
    "        y_graph[i] = twoLayerReluNet(alpha_m,a,w,b,x_graph[i])\n",
    "\n",
    "    return np.min(y_graph), np.max(y_graph)\n",
    "\n",
    "\n",
    "x_graph = np.linspace(-0.5, 0.5, 400)\n",
    "# Initialize an array to store y values\n",
    "min_y_values = np.zeros((int)(n_steps/1000))\n",
    "max_y_values = np.zeros((int)(n_steps/1000))\n",
    "for n in range((int)(n_steps/1000)):\n",
    "    min_y_values[n], max_y_values[n] = get_values(n*1000)\n",
    "\n",
    "# Create an array of indices\n",
    "indices = np.arange(n_steps/1000)\n",
    "\n",
    "# Plot the min and max values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(indices, min_y_values, color='blue', label='Min y values')\n",
    "plt.plot(indices, max_y_values, color='red', label='Max y values')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Index x1000')\n",
    "plt.ylabel('y values')\n",
    "plt.title('Min and Max y values at index')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
